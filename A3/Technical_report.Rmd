---
title: "Assignment Three : Technical Report"
author: "Ghazal Ayobi and Shah Ali Gardezi"
date: "2/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

The aim of this project is to build a model to predict fast growth firms using the Bisnode firms data. In order to build the model we used the mentioned datasheet which contains detailed information about all middle sized registered European companies. The data set contains detailed description of the companies from 2005-2016 for some industries like manufacturing(Electronic and optical, Electrical Equipment, machinery) and services(accommodation, and food and average service activities). In this project we focus on the cross-section of the companies in 2012 whether they have fast growing or no. The Business Question we would ask is whether these companies had fast growth in two subsequent years or no. The prediction for this project was built on several characteristics of the companies such financial, profit and loss statement, balance sheet, and firm features. The main aim of this case study is to build a classification model to differentiate between fast and non-fast growing firms. We used 7 different models including OLS, LASSO, Random Forest and OLS logit. As result of the above model the best selected model was Model 3 with RMSE of 0.361 and AUC was 0.6576 and the average expected loss was 0.3076. Moreover, we the best selected model for both services and Manufacture where we received the following results. The main aim of the project is to choose a prediction model which assists the decision makers on their investment in a company. Moreover, we also checked the selected our model performance for manufacturing and service industries. For the manufacturing industry the RMSE was 0.3771520, AUC was 0.6413224 and average expected loss was 0.3338673. For the service industry the RMSE is 0.344, AUC is	0.691 and the expected loss is	0.273




## Introdction

This study focuses on the firms from 2010 to 2015 mainly the firms had high  growth rate from 2012 to 2014. In order to classify firms as fast growing and not fast growing we minimized the average expected loss and applied the appropriate threshold to assist investment decisions. Moreover, the main aim of this case study is to build a prediction model which can support individuals in their investment decisions in choosing between fast and non-fast growing firms. To classify firms in the mentioned categories, we need a loss function which quantifies the consequences of the decisions that are driven by the prediction (Gabors, 2021). The loss function has two values, one is a loss due to the false negative and a loss due to the false positive. For this purpose we considered these features of the companies and build 7 different models which are OLS, LASSO, Random Forest and OLS Logit. The data comes form the Bisnode, a company that offers decision support in forms of digital business, marketing and credit information. The data set contains detailed description of the companies from 2005-2016 for some industries in manufacturing and services. In this study we focus on the cross section of the companies in 2012, we will ask weather they are fast growing or not in the subsequent years. 


## Label Engineering

Before start of modeling it is vital to define our _y_ variable and start with feature engineering. Based on the Business question we would to build a model to predict fast and non-fast growing firms. Thus, it is important to define what is considered as fast growing firm. For this purpose we consider CAGR, To start with label engineering we define _y_ variable which is whether a company is a fast growing or non-fast growing. Thus, we use compound annual growth rate (CAGR) to be 28% or more. The reason is that on average small or mid-size firms in their initial years have higher annual growth rate than the large companies. Thus, in order to consider a small or mid-size firm as fast growing, we expect it to have CAGR of 28% or more across two years. Thus we define fast growing firms if their CAGR sales value is 28% or more for this purpose we are focusing on the mid and small size firms we only kept the sales between 10 million and 1000 euros.

```{r message=FALSE, warning=FALSE, include=FALSE}


# Please change dir to your own and unzip bisnode firm panel data in data/raw folder

# Import libraries
library(tidyverse)

library(tinytex)
library(haven)
library(glmnet)
library(purrr)
library(margins)
library(skimr)
library(kableExtra)
library(Hmisc)
library(cowplot)
library(gmodels) 
library(lspline)
library(sandwich)
library(modelsummary)
library(viridis)
library(rattle)
library(caret)
library(pROC)
library(ranger)
library(rpart)
library(partykit)
library(rpart.plot)
library(viridis)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Set up environment ------------------------------------------------------

rm(list=ls())

getwd()

dir <- "/Users/ghazalayobi/DA3/A3/"

source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/theme_bg.R")
source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/da_helper_functions.R")

data_in <- paste0(dir,"data/raw/")
data_out <- paste0(dir,"data/clean/")

data <- read_csv(paste0(data_in,"cs_bisnode_panel.csv"))


to_filter <- sapply(data, function(x) sum(is.na(x)))
sort(to_filter[to_filter > 0])

# drop variables with too many NAs more than 200k and filter years between 2012-2014 
# with full year balance sheet indicating they are not new firms
data <- data %>%
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages, D)) %>%
  filter(year >= 2010,
         year <= 2015)

###########################################################
# label engineering
###########################################################

# generate status_alive to check the firm is still alive
data  <- data %>%
  mutate(status_alive = sales > 0 & !is.na(sales) %>%
           as.numeric(.))


# Create log sales and sales in million
# We have negative sales values
summary(data$sales)

data <- data %>%
  mutate(sales = ifelse(sales < 0, 1, sales),
         ln_sales = ifelse(sales > 0, log(sales), 0),
         sales_mil=sales/1000000,
         sales_mil_log = ifelse(sales > 0, log(sales_mil), 0))

data$sales_mil_log_sq <- (data$sales_mil_log)^2 


# Filter out non-alive firms
data <- data %>%
  filter(status_alive == 1) %>%
  # look at firms below 10m euro revenues and above 1000 euros
  filter(!(sales_mil > 10)) %>%
  filter(!(sales_mil < 0.001))


# Keep only firms with data for the 3 years
data <- data %>% group_by(comp_id) %>% filter(n() == 6)

# Change in sales
data <- data %>%
  group_by(comp_id) %>%
  mutate(d1_sales_mil_log = sales_mil_log - Lag(sales_mil_log, 1) ) %>%
  ungroup()


# replace w 0 for new firms + add dummy to capture it
data <- data %>%
  mutate(age = (year - founded_year) %>%
           ifelse(. < 0, 0, .),
         new = as.numeric(age <= 1) %>% #  (age could be 0,1 )
           ifelse(balsheet_notfullyear == 1, 1, .),
         d1_sales_mil_log = ifelse(new == 1, 0, d1_sales_mil_log),
         new = ifelse(is.na(d1_sales_mil_log), 1, new),
         d1_sales_mil_log = ifelse(is.na(d1_sales_mil_log), 0, d1_sales_mil_log))

data <- data %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_sq = d1_sales_mil_log_mod^2
  )



# CAGR sales change in the last 2 years
data <- data %>%
  group_by(comp_id) %>%
  mutate(cagr_sales = ((lead(sales_mil,2) / sales_mil)^(1/2)-1)*100)

data <- data %>%
  filter(year == 2012,
         cagr_sales != is.na(cagr_sales),
         cagr_sales <= 200)

describe(data$cagr_sales)
describe(data$comp_id)

ggplot(data=data, aes(x=cagr_sales)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "black", fill = "#440154", alpha = 0.8) +
  coord_cartesian(xlim = c(-100, 200)) +
  labs(x = "CAGR growth",y = "Percent")+
  theme_bw() 

# Create fast growth dummy
data <- data %>%
  group_by(comp_id) %>%
  mutate(fast_growth = (cagr_sales > 28) %>%
           as.numeric(.)) %>%
  ungroup()

describe(data$fast_growth)

data <- data %>%
  mutate(age = (year - founded_year))



###########################################################
# Feature engineering
###########################################################

# change some industry category codes
data <- data %>%
  mutate(ind2_cat = ind2 %>%
           ifelse(. > 56, 60, .)  %>%
           ifelse(. < 26, 20, .) %>%
           ifelse(. < 55 & . > 35, 40, .) %>%
           ifelse(. == 31, 30, .) %>%
           ifelse(is.na(.), 99, .)
  )

table(data$ind2_cat)

# Firm characteristics
data <- data %>%
  mutate(age2 = age^2,
         foreign_management = as.numeric(foreign >= 0.5),
         gender_m = factor(gender, levels = c("female", "male", "mix")),
         m_region_loc = factor(region_m, levels = c("Central", "East", "West")))

```



```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(data=data, aes(x=sales_mil)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.1,
                 color = "white", fill = "#440154") +
  coord_cartesian(xlim = c(0, 5)) +
  labs(x = "sales in million",y = "Percent", title = "Distribution of Sales")+
  theme_bw() 

ggplot(data=data, aes(x=sales_mil_log)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.25,
                 color = "white", fill = "#440154") +
  labs(x = "log sales in million",y = "Percent", title = "Distribution of log Sales")+
  theme_bw()
```

As the above graph shows that the distribution of sales is skewed to the right and log of sales has a close to normal distribution. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(data=data, aes(x=cagr_sales)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "white", fill = "#440154") +
  coord_cartesian(xlim = c(-100, 200)) +
  labs(x = "CAGR growth",y = "Percent", title = "Distribution of CAGR growth")+
  theme_bw() 
```


## Sample Design 

the Bisnode data set contains 287829 observations and 48 variables. we only kept observation from 2010 to 
The second task of the project is deciding which firms to keep in the data. As our main focus is on the small and mid-size enterprises captured by 28% of their CAGR sales. To narrow our focus we only kept the companies which had sales between 10 million and 1000 euros in 2012. As a result of the sample design we ended up with 10462 observations and 117 variables. The main goal  of the sample design is to reduce impact of extreme values. Moreover, we added another filter to make sure than companies are still in the market indicating that they are still alive, we filtered the data for the alive status firms.    

## Feature Engineering

The third task in the case study is feature engineering, which consists of selecting _x_ variables, cleaning them and putting them in appropriate forms for the prediction model. The variables have different characteristics such about the firm which are the firm size, financial factors, human resource and others. The main part of feature engineering is to decide what functional forms of variables should be included. Some of the variables are as following: 

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot( data = data, aes( x = curr_assets ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 1000000)) +
  scale_y_continuous(limits = c(0, 2800)) +
  labs( x='', y="Count", title= 'Current assets') +
  theme_bw()

ggplot( data = data, aes( x = curr_liab ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 1000000)) +
  scale_y_continuous(limits = c(0, 2800)) +
  labs( x='', y="Count", title= 'Current Liabilities') +
  theme_bw()

ggplot( data = data, aes( x = inventories ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(0, 100000)) +
  scale_y_continuous(limits = c(0, 2000)) +
  labs( x='', y="Count", title= 'Inventories') +
  theme_bw()

ggplot( data = data, aes( x = extra_inc ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 50000)) +
  scale_y_continuous(limits = c(0, 200)) +
  labs( x='', y="", title= 'Extra Income') +
  theme_bw()

```


The above figure shows that most of the variables from the data set have skewed distribution. there are a wide range of potential extreme values which also contains errors and unusual values. It is vital to check the distribution of main variables before assigning a functional form. There are various ways to address such values. Such as: grouping the factor variables, transforming the function to its logarithmic form and another method used by the Gabor, 2021 is winsorization. which states that it is a process where for each variable we identify a threshold value and replace values outside that threshold with threshold values itself and adding a flag variables. Thus, we created some new variables based on the result of the distribution of the main financial variables. For example, different types of assets are expected to be positive, thus, we added flag asset to identify assets more than zero. Moreover, we assigned zero for all the assets intangible, current and fixed, for less than negative values. Moreover, we created new columns for all the profit and loss variables and scaled them by dividing the variables by sales and we created another balance sheet ratio variables by dividing the variables on total assets. Moreover, as these ratios contains variation thus, based on the firms nature and we winsorized them and keep the ratios between -1 and 1. Moreover, we also identify counting variables which cannot be less than zero and created a flag variable as _flag_error_ to identify such values. In addition, we created a balance sheet variable which sums all of the total assets. To capture non-linearity we also added some variables in the square and quadratic terms. 

```{r message=FALSE, warning=FALSE, include=FALSE}
###########################################################
# look at more financial variables, create ratios
###########################################################

# assets can't be negative. Change them to 0 and add a flag.
data <-data  %>%
  mutate(flag_asset_problem=ifelse(intang_assets<0 | curr_assets<0 | fixed_assets<0,1,0  ))
table(data$flag_asset_problem)

data <- data %>%
  mutate(intang_assets = ifelse(intang_assets < 0, 0, intang_assets),
         curr_assets = ifelse(curr_assets < 0, 0, curr_assets),
         fixed_assets = ifelse(fixed_assets < 0, 0, fixed_assets))

# generate total assets
data <- data %>%
  mutate(total_assets_bs = intang_assets + curr_assets + fixed_assets)
summary(data$total_assets_bs)


pl_names <- c("extra_exp","extra_inc",  "extra_profit_loss", "inc_bef_tax" ,"inventories",
              "material_exp", "profit_loss_year", "personnel_exp")
bs_names <- c("intang_assets", "curr_liab", "fixed_assets", "liq_assets", "curr_assets",
              "share_eq", "subscribed_cap", "tang_assets" )

# divide all pl_names elements by sales and create new column for it
data <- data %>%
  mutate_at(vars(pl_names), funs("pl"=./sales))

# divide all bs_names elements by total_assets_bs and create new column for it
data <- data %>%
  mutate_at(vars(bs_names), funs("bs"=ifelse(total_assets_bs == 0, 0, ./total_assets_bs)))


########################################################################
# creating flags, and winsorizing tails
########################################################################

# Variables that represent accounting items that cannot be negative (e.g. materials)
zero <-  c("extra_exp_pl", "extra_inc_pl", "inventories_pl", "material_exp_pl", "personnel_exp_pl",
           "curr_liab_bs", "fixed_assets_bs", "liq_assets_bs", "curr_assets_bs", "subscribed_cap_bs",
           "intang_assets_bs")

data <- data %>%
  mutate_at(vars(zero), funs("flag_high"= as.numeric(.> 1))) %>%
  mutate_at(vars(zero), funs(ifelse(.> 1, 1, .))) %>%
  mutate_at(vars(zero), funs("flag_error"= as.numeric(.< 0))) %>%
  mutate_at(vars(zero), funs(ifelse(.< 0, 0, .)))



# for vars that could be any, but are mostly between -1 and 1
any <-  c("extra_profit_loss_pl", "inc_bef_tax_pl", "profit_loss_year_pl", "share_eq_bs")

data <- data %>%
  mutate_at(vars(any), funs("flag_low"= as.numeric(.< -1))) %>%
  mutate_at(vars(any), funs(ifelse(.< -1, -1, .))) %>%
  mutate_at(vars(any), funs("flag_high"= as.numeric(.> 1))) %>%
  mutate_at(vars(any), funs(ifelse(.> 1, 1, .))) %>%
  mutate_at(vars(any), funs("flag_zero"= as.numeric(.== 0))) %>%
  mutate_at(vars(any), funs("quad"= .^2))


# dropping flags with no variation
variances<- data %>%
  select(contains("flag")) %>%
  apply(2, var, na.rm = TRUE) == 0

data <- data %>%
  select(-one_of(names(variances)[variances]))

########################################################################
# additional
# including some imputation
########################################################################

# CEO age
data <- data %>%
  mutate(ceo_age = year-birth_year,
         flag_low_ceo_age = as.numeric(ceo_age < 25 & !is.na(ceo_age)),
         flag_high_ceo_age = as.numeric(ceo_age > 75 & !is.na(ceo_age)),
         flag_miss_ceo_age = as.numeric(is.na(ceo_age)))

data <- data %>%
  mutate(ceo_age = ifelse(ceo_age < 25, 25, ceo_age) %>%
           ifelse(. > 75, 75, .) %>%
           ifelse(is.na(.), mean(., na.rm = TRUE), .),
         ceo_young = as.numeric(ceo_age < 40))

# number emp, very noisy measure
data <- data %>%
  mutate(labor_avg_mod = ifelse(is.na(labor_avg), mean(labor_avg, na.rm = TRUE), labor_avg),
         flag_miss_labor_avg = as.numeric(is.na(labor_avg)))

summary(data$labor_avg)
summary(data$labor_avg_mod)

data <- data %>%
  select(-labor_avg)

# create factors
data <- data %>%
  mutate(urban_m = factor(urban_m, levels = c(1,2,3)),
         ind2_cat = factor(ind2_cat, levels = sort(unique(data$ind2_cat))))

data <- data %>%
  mutate(fast_growth_f = factor(fast_growth, levels = c(0,1)) %>%
           recode(., `0` = 'no_fast_growth', `1` = "fast_growth"))

# no more imputation, drop obs if key vars missing
data <- data %>%
  filter(!is.na(liq_assets_bs),!is.na(foreign), !is.na(ind))

# drop missing
data <- data %>%
  filter(!is.na(age),!is.na(foreign), !is.na(material_exp_pl), !is.na(m_region_loc))
Hmisc::describe(data$age)

# drop unused factor levels
data <- data %>%
  mutate_at(vars(colnames(data)[sapply(data, is.factor)]), funs(fct_drop))

income_before <- ggplot(data = data, aes(x=inc_bef_tax_pl, y=as.numeric(fast_growth))) +
  geom_point(size=2,  shape=20, stroke=2, fill="blue", color="blue") +
  geom_smooth(method="loess", se=F, colour="black", size=1.5, span=0.9) +
  labs(x = "Income before taxes",y = "Fast Growth distribution") +
  theme_bw() +
  scale_x_continuous(limits = c(-1.5,1.5), breaks = seq(-1.5,1.5, 0.5))

```



The curve below shows the relationship between income before taxes and the fast and non fast growing firms.

```{r echo=FALSE, message=FALSE, warning=FALSE}
income_before
```

Other flag variables were created to identify the age of CEU of the firm and other variables such as type of industry were transformed to the factors and as result missing variables were addressed in multiple ways such as imputation, dropping. as a result of data cleaning, munging, imputation, and removing null variables, we have 10462 observations and 117 variables. 


# Variables Description


```{r echo=FALSE, message=FALSE, warning=FALSE}

data_description <- data.frame("Group" = c('Raw variables', 'Engine Varaibles 1', 'Engine Varaibles 2', 'Engine Varaibles 3', "Growth(d1)", 'Human Resource', 'Firm', "Interaction 1 and 2"),
                                  "Variables" = c("sales, fixed, liquid, current, intangible assets, current liabilities, inventories, equity shares, subscribed capital, sales revenues, income before tax, extra income, material, personal and extra expenditure, extra profit", 
                                               
                                                
                                                 "All raw variables of balance sheet and profit and loss elements as Winsorized financial variables", 
                                                
                                                
                                                "quadratic terms created for profit and loss, extra profit and loss, income before tax, and share equity", 
                                                
                                                
                                                "Flags (extreme, low, high, zero) of all applicable variables", 
                                                
                                                
                                                "Sales growth is captured by a winsorized growth variable, its quadratic term and flags for extreme low and high values", 
                                                
                                                
                                                "For the CEO: female dummy, winsorized age and flags, flag for missing information; foreign management dummy; labor cost, and flag for missing labor cost information",
                                                
                                                
                                                "Age of firm, squared age, a dummy if newly established, industry categories, location regions for its headquarters, and dummy if located in a big city",
                                                
                                                
                                                "Interactions with sales growth, firm size, and industry"))

data_table_viewxx <- data_description %>%
  kbl(caption = "Firm Exit Predictor Variables") %>%
  kable_minimal(full_width = F, html_font = "Cambria")


```

# Modeling 

Based on the defined business question the main aim of this project is to build a prediction model to identify fast and non-fast growing firms. For this purpose we use compound annual growth rate with a threshold of 28% over the period of two years 2012 to 2014. Based on the business question we identify the firms as fast growing which performs more than the above growth rate. The table below shows that based on define criteria 16.5% of the firms have fast growth rate. The reason behind considering two years interval from 2012 to 2014. it is difficult to identify firms as fast and not fast growing based on the coverage of one year. Two years gives a more detailed and cumulative growth rate for the considered firms. As the firms grow they maitain their growth from the first year to the second, thus, two year sales CAGR is taken to identify fast growing firms. 

```{r include=FALSE}
rm(list=ls())

# Import libraries
library(haven)
library(glmnet)
library(purrr)
library(margins)
library(skimr)
library(kableExtra)
library(Hmisc)
library(cowplot)
library(gmodels) 
library(lspline)
library(sandwich)
library(modelsummary)
library(viridis)
library(rattle)
library(caret)
library(pROC)
library(ranger)
library(rpart)
library(partykit)
library(rpart.plot)


# set working directory
# load functions
source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/theme_bg.R")
source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/da_helper_functions.R")


# Please change path to yours

path <- "/Users/ghazalayobi/DA3/A3/"
data_in <- paste0(path,"data/clean/")
data_out <- data_in
output <- paste0(path,"output/")
create_output_if_doesnt_exist(output)

data <- readRDS(paste0(data_in,"bisnode_firms_clean.rds"))

# Define variable sets ----------------------------------------------
# (making sure we use ind2_cat, which is a factor)

rawvars <-  c("curr_assets", "curr_liab", "extra_exp", "extra_inc", "extra_profit_loss", "fixed_assets",
              "inc_bef_tax", "intang_assets", "inventories", "liq_assets", "material_exp", "personnel_exp",
              "profit_loss_year", "sales", "share_eq", "subscribed_cap")
qualityvars <- c("balsheet_flag", "balsheet_length", "balsheet_notfullyear")
engvar <- c("total_assets_bs", "fixed_assets_bs", "liq_assets_bs", "curr_assets_bs",
            "share_eq_bs", "subscribed_cap_bs", "intang_assets_bs", "extra_exp_pl",
            "extra_inc_pl", "extra_profit_loss_pl", "inc_bef_tax_pl", "inventories_pl",
            "material_exp_pl", "profit_loss_year_pl", "personnel_exp_pl")
engvar2 <- c("extra_profit_loss_pl_quad", "inc_bef_tax_pl_quad",
             "profit_loss_year_pl_quad", "share_eq_bs_quad")
engvar3 <- c(grep("*flag_low$", names(data), value = TRUE),
             grep("*flag_high$", names(data), value = TRUE),
             grep("*flag_error$", names(data), value = TRUE),
             grep("*flag_zero$", names(data), value = TRUE))
d1 <-  c("d1_sales_mil_log_mod", "d1_sales_mil_log_mod_sq",
         "flag_low_d1_sales_mil_log", "flag_high_d1_sales_mil_log")
hr <- c("female", "ceo_age", "flag_high_ceo_age", "flag_low_ceo_age",
        "flag_miss_ceo_age", "ceo_count", "labor_avg_mod",
        "flag_miss_labor_avg", "foreign_management")
firm <- c("age", "age2", "new", "ind2_cat", "m_region_loc", "urban_m")

# interactions for logit, LASSO
interactions1 <- c("ind2_cat*age", "ind2_cat*age2",
                   "ind2_cat*d1_sales_mil_log_mod", "ind2_cat*sales_mil_log",
                   "ind2_cat*ceo_age", "ind2_cat*foreign_management",
                   "ind2_cat*female",   "ind2_cat*urban_m", "ind2_cat*labor_avg_mod")
interactions2 <- c("sales_mil_log*age", "sales_mil_log*female",
                   "sales_mil_log*profit_loss_year_pl", "sales_mil_log*foreign_management")


X1 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "ind2_cat")
X2 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "fixed_assets_bs","share_eq_bs","curr_liab_bs ",   "curr_liab_bs_flag_high ", "curr_liab_bs_flag_error",  "age","foreign_management" , "ind2_cat")
X3 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar,                   d1)
X4 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars)
X5 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars, interactions1, interactions2)

# for LASSO
logitvars <- c("sales_mil_log", "sales_mil_log_sq", engvar, engvar2, engvar3, d1, hr, firm, qualityvars, interactions1, interactions2)

# for RF (no interactions, no modified features)
rfvars  <-  c("sales_mil", "d1_sales_mil_log", rawvars, hr, firm, qualityvars)


# Check simplest model X1
ols_modelx1 <- lm(formula(paste0("fast_growth ~", paste0(X1, collapse = " + "))),
                  data = data)
summary(ols_modelx1)

glm_modelx1 <- glm(formula(paste0("fast_growth ~", paste0(X1, collapse = " + "))),
                   data = data, family = "binomial")
summary(glm_modelx1)


# Check model X2
glm_modelx2 <- glm(formula(paste0("fast_growth ~", paste0(X2, collapse = " + "))),
                   data = data, family = "binomial")
summary(glm_modelx2)

#calculate average marginal effects (dy/dx) for logit
mx2 <- margins(glm_modelx2)

sum_table <- summary(glm_modelx2) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(mx2)[,c("factor","AME")])

kable(x = sum_table, format = "latex", digits = 3,
      col.names = c("Variable", "Coefficient", "dx/dy"),
      caption = "Average Marginal Effects (dy/dx) for Logit Model") %>%
  cat(.,file= paste0(output,"AME_logit_X2.tex"))


# baseline model is X4 (all vars, but no interactions) -------------------------------------------------------

ols_model <- lm(formula(paste0("fast_growth ~", paste0(X4, collapse = " + "))),
                data = data)
summary(ols_model)

glm_model <- glm(formula(paste0("fast_growth ~", paste0(X4, collapse = " + "))),
                 data = data, family = "binomial")
summary(glm_model)

#calculate average marginal effects (dy/dx) for logit
# vce="none" makes it run much faster, here we do not need variances

m <- margins(glm_model, vce = "none")

sum_table2 <- summary(glm_model) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate, `Std. Error`) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(m)[,c("factor","AME")])

kable(x = sum_table2, format = "latex", digits = 3,
      col.names = c("Variable", "Coefficient", "SE", "dx/dy"),
      caption = "Average Marginal Effects (dy/dx) for Logit Model") %>%
  cat(.,file= paste0(output,"AME_logit_X4.tex"))


```


```{r echo=FALSE, message=FALSE, warning=FALSE}
summ<- datasummary((`Growth` = as.factor(fast_growth_f)) ~ N + Percent(), data = data, title = "Firm Growth Summary")
summ
```

## Set up
The best model gives the best prediction in the live data. Before turning to the modeling part of the project, it is worth mentioning that in order to avoid over fitting, the original data is split into two random parts by 20% to 80% ratio. Holdout set contains the 20% and the rest is work data set. For the training set we use 5-fold cross validation, this means splitting the train data into five random samples and calculating and deciding based on the average of 5 CV RMSE result. 

## Probability Prediction and Model selection
### Probability Logit Models
For this case study we performed probability prediction by logit and as result selecting the best logit model by cross-validation and evaluate the Model by the holdout, manufacturing and service data sets. Five different logit models are considered ranked from simplest to the most complex one were used to find a better model to use for further analysis. The M1 logit model includes variables based on the domain knowledge, we included variable which we considered to be important. The variables in each model are as following: 


```{r echo=FALSE}
model_variables <- data.frame ( "Models" = c("M1 : Log sales + Log sales sq + Change in sales + Profit and loss + Industry", "M2 :M1 + Fixed assets + Equity + Current liabilities + Age + Foreign management", "M3 : Log sales + Log sales sq + Firm + Engine variables 1 + D1", "M4 : M3 + Engine variables 2 + Engine variables 3 + HR", "M5 : M4 + Interactions 1 and 2", "LASSO logit : same as M5", "Random Forest : Log sales + Log sales sq, Raw variables, human resouce, and frim "))

model_table_viewxx <- model_variables %>%
  kbl(caption = "Firm Exit Predictor Variables") %>%
  kable_minimal(full_width = F, html_font = "Cambria")
```



To compare the models we require a standardized measure to select the best model among the created models. Two vital measurement for this purpose is Root mean squared error (RMSE) and area under the Curve (AUC) which allows us to select he best model. The below table shows the result from RMSE and AUCA for the five logit models. The below table is the result of RMSE and AUC for all of the five logit Models. it can be seen from the result that RMSE result have very small differences. Thus, RMSE is the lowest for the Model X3 and X4 same as AUC. For this case study, we consider X3 as it has the lowest RMSE compared to X4 by 0.00028 and it has a simple form compared to X4. For further analysis we will consider model 3. 



```{r include=FALSE}
set.seed(123456)

train_indices <- as.integer(createDataPartition(data$fast_growth, p = 0.8, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]

dim(data_train)
dim(data_holdout)

Hmisc::describe(data$fast_growth_f)
Hmisc::describe(data_train$fast_growth_f)
Hmisc::describe(data_holdout
                $fast_growth_f)

#######################################################x
# PART I PREDICT PROBABILITIES
# Predict logit models ----------------------------------------------
#######################################################x

# 5 fold cross-validation
train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummaryExtended,
  savePredictions = TRUE
)


# Train Logit Models ----------------------------------------------

logit_model_vars <- list("X1" = X1, "X2" = X2, "X3" = X3, "X4" = X4, "X5" = X5)

CV_RMSE_folds <- list()
logit_models <- list()

for (model_name in names(logit_model_vars)) {
  
  features <- logit_model_vars[[model_name]]
  
  set.seed(123456)
  glm_model <- train(
    formula(paste0("fast_growth_f ~", paste0(features, collapse = " + "))),
    method = "glm",
    data = data_train,
    family = binomial,
    trControl = train_control
  )
  
  logit_models[[model_name]] <- glm_model
  # Calculate RMSE on test for each fold
  CV_RMSE_folds[[model_name]] <- glm_model$resample[,c("Resample", "RMSE")]
  
}

# Logit lasso -----------------------------------------------------------

lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)

set.seed(123456)
system.time({
  logit_lasso_model <- train(
    formula(paste0("fast_growth_f ~", paste0(logitvars, collapse = " + "))),
    data = data_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action=na.exclude
  )
})

tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))
write.csv(lasso_coeffs, paste0(output, "lasso_logit_coeffs.csv"))

CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]



```


```{r echo=FALSE, message=FALSE, warning=FALSE}


#############################################x
# PART I
# No loss fn
########################################

# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()

for (model_name in names(logit_models)) {
  
  auc <- list()
  model <- logit_models[[model_name]]
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)
    
    roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
    auc[[fold]] <- as.numeric(roc_obj$auc)
  }
  
  CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
                                           "AUC" = unlist(auc))
}

# For each model: average RMSE and average AUC for models ----------------------------------

CV_RMSE <- list()
CV_AUC <- list()

for (model_name in names(logit_models)) {
  CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
  CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}

# We have 6 models, (5 logit and the logit lasso). For each we have a 5-CV RMSE and AUC.
# We pick our preferred model based on that. -----------------------------------------------

nvars <- lapply(logit_models, FUN = function(x) length(x$coefnames))
nvars[["LASSO"]] <- sum(lasso_coeffs != 0)

logit_summary1 <- data.frame("Number of predictors" = unlist(nvars),
                             "CV RMSE" = unlist(CV_RMSE),
                             "CV AUC" = unlist(CV_AUC))

kable(x = logit_summary1, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Number of predictors","CV RMSE","CV AUC")) %>%
  cat(.,file= paste0(output, "logit_summary1.tex"))


logit_summary1 %>% 
  slice(1:5) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```



### LASSO MODEL

The set of models in this section includes LASSO for logit. Our Logit Model 5, includes all our variables and interactions. In this section we use this group of variables in the LASSO algorithm to select variables meaning shrink the coefficientsin order to have a better predictive model. As a result LASSO produces a model that includes most of the variables, however it also drop some variables. Based on the below result we can say that LASSO performs well while in RMSE, on the other hand the third simple logit model has better result for AUC. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
logit_summary1 %>% 
  slice(c(3,6)) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```


### Random Forest

For this case study the last model is (probability) Random Forest using the set of variables for the random forest from the model section. These variables are raw variables, human resource, and firm variables. Moreover, the variables in the random forest does not have any patterns because Random forest can assign functional forms and interactions. We set the random forest tuning parameter to be either 5, 6, or 7 in each split. The result from the Random Forest indicates that (probability) Random Forest outperforms other models such as LASSO and probability logit by around -0.001 RMSE and the AUC result  is higher than the both mentioned model 3 and LASSO logit. As a result the Random Forest based on the RMSE and AUC result is the best performing model. Thus, we use our holdout set to draw ROC curve.


```{r message=FALSE, warning=FALSE, include=FALSE}
# 5 fold cross-validation
train_control <- trainControl(
  method = "cv",
  n = 5,
  classProbs = TRUE, # same as probability = TRUE in ranger
  summaryFunction = twoClassSummaryExtended,
  savePredictions = TRUE
)
train_control$verboseIter <- TRUE
tune_grid <- expand.grid(
  .mtry = c(5, 6, 7),
  .splitrule = "gini",
  .min.node.size = c(10, 15)
)
# build rf model
set.seed(2021)
rf_model_p <- train(
  formula(paste0("fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = data_train,
  tuneGrid = tune_grid,
  trControl = train_control,
)
best_mtry <- rf_model_p$bestTune$mtry
best_min_node_size <- rf_model_p$bestTune$min.node.size


# Get average (ie over the folds) RMSE and AUC ------------------------------------

CV_RMSE_folds[["rf_p"]] <- rf_model_p$resample[,c("Resample", "RMSE")]
auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(Resample == fold)
  
  roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p"]] <- data.frame("Resample" = names(auc),
                                     "AUC" = unlist(auc))

CV_RMSE[["Random_forest"]] <- mean(CV_RMSE_folds[["rf_p"]]$RMSE)
CV_AUC[["Random_forest"]] <- mean(CV_AUC_folds[["rf_p"]]$AUC)

rf_summary <- data.frame("CV RMSE" = unlist(CV_RMSE),
                         "CV AUC" = unlist(CV_AUC))
rf_summary %>% 
  slice(c(3,7)) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria")

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
rf_summary %>% 
  slice(c(3,7)) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```


### ROC Curve

The ROC curve is a widely used tool that graphically presents the trade-off between false positive and false negative that arise when we apply different classification thresholds to the probability predictions from an estimated model. Moreover, the ROC curve shows false positive among all y = 0 observations and and the proportion of the true positive among all y = 1 observations. (Gabors, 2021). Thus, we draw the ROC curve for the selected model which is the Rnadom Forest. Below are the two versions of the ROC curve. The ROC curve points for the various thresholds show the values between 0.05 and 0.75 by steps of 0.025. The mentioned curve also utilizes color coding to show the approximate values of the related threshold, as of the moment the point are not shown. The below curve on the below right is similar to common ROC curve. The main important point in this curve is it fill in for the threshold values, however it does not have any points to indicate the threshold values. Based on the result from our best model of Random Forest its AUC is 0.67. A higher threshold means fewer false positive or fewer true positive, on the other hand, a lower threshold indicates more true positive and more false positive. Thus, by looking to the below curves, we require to set a threshold, for which we need to create the loss function. 


```{r echo=F, message=FALSE, warning=FALSE, out.width="50%"}


best_no_loss <- rf_model_p

predicted_probabilities_holdout <- predict(best_no_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_no_loss_pred"] <- predicted_probabilities_holdout[,"fast_growth"]
# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------
thresholds <- seq(0.05, 0.75, by = 0.025)
cm <- list()
true_positive_rates <- c()
false_positive_rates <- c()
for (thr in thresholds) {
  holdout_prediction <- ifelse(data_holdout[,"best_no_loss_pred"] < thr, "no_fast_growth", "fast_growth") %>%
    factor(levels = c("no_fast_growth", "fast_growth"))
  cm_thr <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)$table
  cm[[as.character(thr)]] <- cm_thr
  true_positive_rates <- c(true_positive_rates, cm_thr["fast_growth", "fast_growth"] /
                             (cm_thr["fast_growth", "fast_growth"] + cm_thr["no_fast_growth", "fast_growth"]))
  false_positive_rates <- c(false_positive_rates, cm_thr["fast_growth", "no_fast_growth"] /
                              (cm_thr["fast_growth", "no_fast_growth"] + cm_thr["no_fast_growth", "no_fast_growth"]))
}
tpr_fpr_for_thresholds <- tibble(
  "threshold" = thresholds,
  "true_positive_rate" = true_positive_rates,
  "false_positive_rate" = false_positive_rates
)
ggplot(
  data = tpr_fpr_for_thresholds,
  aes(x = false_positive_rate, y = true_positive_rate, color = threshold)) +
  labs(x = "False positive rate (1 - Specificity)", y = "True positive rate (Sensitivity)") +
  geom_point(size=2, alpha=0.8) +
  scale_color_viridis(option = "D", direction = -1) +
  scale_x_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  scale_y_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  theme_bw() +
  theme(legend.position ="right") +
  theme(legend.title = element_text(size = 4), 
        legend.text = element_text(size = 4),
        legend.key.size = unit(.4, "cm")) 

# continuous ROC on holdout with best model (Logit 4) -------------------------------------------


roc_obj_holdout <- roc(data_holdout$fast_growth, data_holdout$best_no_loss_pred)

createRocPlot(roc_obj_holdout, "best_no_loss_roc_plot_holdout")

```

### Finding the Optimal Classification Threshold

The last part of this case study is to define the loss function. Loss function quantifies the consequences of decisions that are driven by prediction(Gabors, 2021). While classification if binary y variable we can be wrong in two places for false negative classification FN, or making a false positive classification FP. At this point a loss function have only two values, one is a loss due to false negative and the other is loss due to false positive. Based on the previous models we define the loss function as following. It is worth mentioning that we require the loss function to assist decision making. The main goal od this study is to build a model to identify fast growing farms. With the mentioned models we require to find the threshold value for the classification which will result in the smallest expected loss which is called Optimal classification threshold which is shown as following.


$$optimal-classification-threshold = \frac{loss(FP)}{loss(FP) + loss(FN)}$$




Defining loss function with an example. False positive is when we identify a firm as fast growing but it is not. For instance, if an individual invest in this firm which is classified as fast growing but it is not. This indicates that the firm is growing below the given threshold. As a result the individual will not loss their whole investment but a part of revenue. Based on our case study the cost of false positive would be 1000 euros because we classify a firm as fast growing but it is not. On the other hand false positive is we classify a firm as non-fast growing however, in reality it turns out to be fast growing. In this case individuals do not invest in such firms. Thus, cost of FN would be more than more than FP. The cost of false negative would be 2000 euros. Thus we can say the ratio of the costs would 1/2 and the optimal classification threshold is equal to 0.333. Moreover, we decided to run the optimal threshold algorithm the given data set. Below table is the result of the optimal threshold algorithm. We can see that Logit Model 3 and Random Forest Probability have the lowest expected loss. Moreover, Random forest has the lowest RMSE, expected loss, and has the highest AUC and the optimal classification threshold is 0.37 


$$OCT = \frac{1}{1+2} = 0.333$$


```{r include=FALSE}

# Confusion table with different tresholds ----------------------------------------------------------

# fast_growth: the threshold 0.5 is used to convert probabilities to binary classes
class_prediction <- predict(best_no_loss, newdata = data_holdout)
summary(class_prediction)

# confusion matrix: summarize different type of errors and successfully predicted cases
# positive = "yes": explicitly specify the positive case
cm_object1 <- confusionMatrix(class_prediction, data_holdout$fast_growth_f, positive = "fast_growth")
cm1 <- cm_object1$table
cm1


# a sensible choice: mean of predicted probabilities
mean_predicted_fast_growth_prob <- mean(data_holdout$best_no_loss_pred)
mean_predicted_fast_growth_prob
holdout_prediction <-
  ifelse(data_holdout$best_no_loss_pred < mean_predicted_fast_growth_prob, "no_fast_growth", "fast_growth") %>%
  factor(levels = c("no_fast_growth", "fast_growth"))
cm_object2 <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)
cm2 <- cm_object2$table
cm2



##############################################################
#                                                            #
#                           PART IIV                         #
#  ----- Probability prediction with a loss function ------  #
#                                                            #
##############################################################

# Introduce loss function
# relative cost of of a false negative classification (as compared with a false positive classification)
FP=1
FN=2
cost = FN/FP
# the prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))
prevelance = sum(data_train$fast_growth)/length(data_train$fast_growth)


#################################
#        Logit and LASOO        #
#################################

# Draw ROC Curve and find optimal threshold with loss function --------------------------

best_tresholds <- list()
expected_loss <- list()
logit_cv_rocs <- list()
logit_cv_threshold <- list()
logit_cv_expected_loss <- list()

for (model_name in names(logit_models)) {
  
  model <- logit_models[[model_name]]
  colname <- paste0(model_name,"_prediction")
  
  best_tresholds_cv <- list()
  expected_loss_cv <- list()
  
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)
    
    roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
    best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                            best.method="youden", best.weights=c(cost, prevelance))
    best_tresholds_cv[[fold]] <- best_treshold$threshold
    expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
  }
  
  # average
  best_tresholds[[model_name]] <- mean(unlist(best_tresholds_cv))
  expected_loss[[model_name]] <- mean(unlist(expected_loss_cv))
  
  # for fold #5
  logit_cv_rocs[[model_name]] <- roc_obj
  logit_cv_threshold[[model_name]] <- best_treshold
  logit_cv_expected_loss[[model_name]] <- expected_loss_cv[[fold]]
  
}

logit_summary2 <- data.frame("Avg of optimal thresholds" = unlist(best_tresholds),
                             "Threshold for Fold5" = sapply(logit_cv_threshold, function(x) {x$threshold}),
                             "Avg expected loss" = unlist(expected_loss),
                             "Expected loss for Fold5" = unlist(logit_cv_expected_loss))





#################################
#         Random forest         #
#################################
# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)
  
  roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevelance))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
}

# average
best_tresholds[["rf_p"]] <- mean(unlist(best_tresholds_cv))
expected_loss[["rf_p"]] <- mean(unlist(expected_loss_cv))


# Save output --------------------------------------------------------
# Model selection is carried out on this CV RMSE

nvars[["rf_p"]] <- length(rfvars)

summary_results <- data.frame("Number of predictors" = unlist(nvars),
                              "CV RMSE" = unlist(CV_RMSE),
                              "CV AUC" = unlist(CV_AUC),
                              "CV threshold" = unlist(best_tresholds),
                              "CV expected Loss" = unlist(expected_loss))

model_names <- c("Logit X1", "Logit X3",
                 "Logit LASSO","RF probability")
summary_results <- summary_results %>%
  filter(rownames(.) %in% c("X1", "X3", "LASSO", "rf_p"))
rownames(summary_results) <- model_names



```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)
summary_results %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```


## Best Model based on Expected Loss

As a result of we can say that Random Forest has the lowest expected loss and RMSE, compared to Logit LASSO, logit Model 3 and logit Model 1. However, logit Model has the similar performance. The expected loss from Model 3 is same as Random forest which is around 0.30764. The RMSE is different by 0.0006 which is a very small number. The reason behind this decision is logit Model 3 is easily interpretative compared to the Random Forest which is black box model.

# Model Evaluation and Confusion Matrix

As we have chosen our best model, we can evaluate the result. As a result we can say that we correctly predicted 83% of the firms. he The accuracy of the model is 83% the model classified correctly 83% of the firms. The specificity of the model is 97% which indicates that from not fast growing firms the model correctly estimated 97%. The sensitivity of the model is 11% which means the model predicted the fast growing firms by 11%. 


```{r echo=FALSE, message=FALSE, warning=FALSE}

best_logit_with_loss <- logit_models[["X3"]]
best_logit_optimal_treshold <- best_tresholds[["X3"]]
logit_predicted_probabilities_holdout <- predict(best_logit_with_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_with_loss_pred"] <- logit_predicted_probabilities_holdout[,"fast_growth"]
# ROC curve on holdout
roc_obj_holdout <- roc(data_holdout$fast_growth, data_holdout[, "best_logit_with_loss_pred", drop=TRUE])
# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$fast_growth)
# Confusion table on holdout with optimal threshold
holdout_prediction <-
  ifelse(data_holdout$best_logit_with_loss_pred < best_logit_optimal_treshold, "no_fast_growth", "fast_growth") %>%
  factor(levels = c("no_fast_growth", "fast_growth"))
cm_object3 <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)
cm3 <- cm_object3$table
cm3 %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```


$$accuracy = \frac{TP + TN}{N} = \frac{1705+38} {2092} = 83\%$$
$$sensitivity = \frac{TP}{TP + FN} = \frac{38} {38 + 302} = 11\%$$
$$specifcity = \frac{TN}{TN + FP} = \frac{1705} {1705 + 47} = 97\%$$



## Industry Analysis

The main data set contained information about two major industries, which we considered them separately. For the both industries we ran the prediction analysis. As a result of the analysis, received the analysis for both industries for logit models one and three, lasso model and random probability forest models. Moreover we used Confusion table on holdout with optimal threshold for the both service and manufacturing industries. The manufacturing firms data set has . From the and The result of Confusion table on holdout with optimal threshold for the manufacturing is as following: The table shows that accuracy of the manufacturing is 78%, sensitivity is 10% and specificity is 95%. The RMSE for the MODE 3 the best selected model in manufacturing industry is 0.377 the area under the curve AUC 0.641 is and the expected loss is 0.333. In the service industry based on the best selected model RMSE is 0.344, AUC is	0.691 and expected loss is 0.273. 

```{r echo=FALSE, message=FALSE, warning=FALSE}

manufac_confusion_mt <- data.frame("Column 1" = c("Prediction", "Prediction Non fast growing", "Prediction fast growing"),
                            "Column 2" = c("Refrence non fast growing", 590, 26),
                            "Column 3" = c("Refrence fast growing", 142, 16))

 manufac_confusion_mt %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```
$$accuracy = \frac{TP + TN}{N} = \frac{590+16} {774} = 78\%$$
$$sensitivity = \frac{TP}{TP + FN} = \frac{16} {16 + 142} = 10\%$$

$$specifcity = \frac{TN}{TN + FP} = \frac{590} {590 + 26} = 95\%$$
The next industry is service industry which contains 6591 observation and 117 columns. The service data set has 5589 non fast growing firms which is around 84% of the service firms, moreover the number of fast growing firms are 1002 which is 15.2% of the all fast growing firms. Moreover we used Confusion table on holdout with optimal threshold for the services the result for the confusion Matrix is the following table. Moreover the accuracy of service industry is 83%. The sensitivity of the service industry using the optimal threshold is 10% and the specificity is 96%. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
service_confusion_mt <- data.frame("Column-1" = c("Prediction", "Prediction Non fast growing", "Prediction fast growing"),
                            "Column-2" = c("Refrence non fast growing", 1081, 34),
                            "Column-3" = c("Refrence fast growing", 181, 22))

service_confusion_mt %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria")

```

$$accuracy = \frac{TP + TN}{N} = \frac{22+1081} {1318} = 83\%$$
$$sensitivity = \frac{TP}{TP + FN} = \frac{22} {22 + 181} = 10\%$$
$$specifcity = \frac{TN}{TN + FP} = \frac{1081} {1081 + 34} = 96\%$$
As a result we can say that based on the accuracy of the model across whole data set and sub sets of manufacturing and services, The complete data set has same accuracy as service industry meaning they classify the right category 83%. However, the manufacturing industry only classified 78% of the firms correctly. The second measurement is sensitivity which is the proportion of true positives among all actual positives. In this case study sensitivity is the actual fast growing firms. Based on the Confusion table on holdout with optimal threshold in main dataset, in the two sub sets of service and manufacture industries, the actual data set predicted 11% of the actual fast growing firms and the other two sub groups performed the same and predicted 10% of the actual fast growing firms. The third classification measurement in the data set is specificity. It means predicting the non fast firms correctly is highest in the main data set, services, and finally manufacturing industry, with specificity of 97%,  96%, and 95% consecutively. As a result the service industry performed better compared to the manufacture industry. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
sum_manu <- read_csv("https://raw.githubusercontent.com/ghazalayobi/DA3/main/A3/output/sum_manufacturing.csv")
 sum_manu %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria")

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
sum_manu <- read_csv("https://raw.githubusercontent.com/ghazalayobi/DA3/main/A3/output/sum_service.csv")
 sum_manu %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria")
```



## Summary 
The final model which was chosen for this case study was Model 3 which has the variable of firm details and engine variables which are firm financial information of balance sheet and profit and loss. The The accuracy of the model is 83% the model classified correctly 83% of the firms. The specificity of the model is 97% which indicates that from not fast growing firms the model correctly estimated 97%. The sensitivity of the model is 11% which means the model predicted the fast growing firms. The result is a helpful tool for the firms to predict which firms are fast and non fast growing. Moreover, we compared across industry result considering the same single loss function and carrying out the exercise for different industries. All result were predicted based on the logit model 3. The performance of whole data and all models were evaluated.




