---
title: "Data Analysis 3 : Assignment II : Business Report"
geometry : margin=1.6cm
fontsize: 9pt
output: 
  pdf_document:
  extra_dependencies: ["flafter"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Clearing the environment
rm(list=ls())
# Loading the Libraries
library(tidyverse)
library(caret)
library(modelsummary)
library(stargazer)
library(xtable)
library(rattle)
library(kableExtra)
library(data.table)
library(ggplot2)
library(GGally)
library(gridExtra)
library(knitr)
library(viridis)
library(directlabels)
library(Hmisc)
library(cowplot)
library(ranger)
library(glmnet)
library(grid)
library(skimr)
library(gbm)
library(fixest)
library(rpart)
library(rpart.plot)

```



```{r include=FALSE}

getwd()

setwd("/Users/ghazalayobi/DA3/A2")
path <- "/Users/ghazalayobi/DA3/A2"

#location folders
data_in  <- paste0(path,"/data/raw/")
data_out <- paste0(path,"/data/clean/")
output <- paste0(path, "/output/")

dfx <- read_csv("https://raw.githubusercontent.com/ghazalayobi/DA3/main/A2/data/clean/airbnb_ny_cleaned.csv")
# github link for clean data()
df <- subset(dfx, select = -c(latitude, longitude))

source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/da_helper_functions.R")
source("https://raw.githubusercontent.com/ghazalayobi/DA3/main/theme_bg.R")

# checking for missing variables
to_filter <- sort(sapply(df, function(x) sum(is.na(x)/nrow(df)*100)))
to_filter[to_filter > 0]

# quick look at data
#glimpse(df)
#skim(df)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
count_rows <- count(df)
count_cols <- ncol(df)
```


## Introduction 

The main goal of this project is to help a company to set price for their new apartments which are not yet in the market.To build a price prediction model for a company which is operating small and mid-size apartments hosting from two to six guests in the New York, the data is taken from Inside Airbnb which can be found [here](http://insideairbnb.com/new-york-city/). As a result of data cleaning, munging, and analysis, five price prediction models, OLS, Lasso, Cart, Random Forest and GBM, Gradient Boosting Machine, are created. As a result GBM showed the best prediction result with 65.38 USD RMSE. The major predictor features are the number of accommodates, number of bathrooms, the number of beds, neighborhood, and amenities such as availability of washer, gym, elevator are the most important. Other characteristics such as days since the first review is also an important predictor. Eventually the final goal of the project is to finalize a better prediction model measured in relative RMSE values. 

## Data Prepration

Before initializing building predictive models, it is vital to clean the data. The original data set in the Airbnb New York consists of 38186 observations and 74 columns.  The data refer to the one night rental prices between January 6 to January 9, 2022. The target variable is price per night per person in US dollars. To transform the original data to tidy data table, the major part of transformation consists of processing _amenities_ column to binary variables. For meaningful grouping similar amenities were grouped together and only binaries between 1% to 99% values are kept in the data set. After merging 3134 amenities with similar attributes it resulted into 90 amenities. For detailed description of data cleaning steps  please find the codes [here](https://github.com/ghazalayobi/DA3/blob/main/A2/codes/1_cleaning_preparing.R). The main goal of the project is to predict prices of apartments which accommodates between 2 to 6 guests, thus the data was filtered accordingly. The key variable, price, contained extreme value and missing observations, thus it was filtered to contain values below 500 USD and dropping the observation where it is missing. As a result of of data cleaning, preparing and munging the total observations are `r count_rows` with `r count_cols` columns.
 
## Feature Engineering

Feature engineering includes what type of predictor variables to include, and deciding about functional forms of predictors and possible interactions. The data is grouped as following:

- **Basic variables** which consists of the main predictors such as: number of accommodates, property types, number of beds, number of days since the first review and flag variable of number of days since the first review to indicate missing. As the focus of project is on small and mid-size apartment thus, property types are as following: Entire home or apartment, serviced apartment, Condominium, and entire rental unit. 

- **Basic addition** this includes key factorized variables, such as, neighborhoods groups, and host response time.

- **Review Variables** consists of the crucial guests reviews predictors such as total number of reviews, number of reviews per month and host review score rating and reviews flags which shows missing variables.

- **Polynomial level** consists of squared terms of guests and squared and cubic terms for days since the first review.

- **Amenities dummies** which consisted of the binary values for all of amenities. 

After the key filters and grouping variables there were 15 variables with missing values. Missing values were addressed as following: first assumption is there is at least one bathroom in each apartment, second assumption is if the number of guests are less than 4 then impute 1, otherwise imputing 2. Missing number of beds were replace with half of number of accommodates, assuming there are double beds in the apartments. It is assumed that the minimum number of nights is one and minimum number of reviews is also 1. Flags were  created to indicate the missing values in the each predictor. As the goal of project is to build price prediction model, it is crucial to check price and log of price distribution. Price distribution shows Airbnb  apartment prices is skewed with a long right tail and the log price is close to normally distributed. In this project, log of price is not considered, prediction is carried out with price for all of the models. 

```{r fig.height=4, message=FALSE, warning=FALSE, include=FALSE, out.width='50%'}
# Histograms

# price -> skewed distribution with long right tail
hist_price <- ggplot(data=df, aes(x=price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "white", fill = "#440154", alpha = 0.7) +
  coord_cartesian(xlim = c(0, 500)) +
  labs(title = "Distribution of New York Airbnb prices",x = "Price (US dollars)",y = "Percent")+
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.10), breaks = seq(0, 0.10, by = 0.03), labels = scales::percent_format(1)) +
  scale_x_continuous(expand = c(0.00,0.00),limits=c(0,500), breaks = seq(0,500, 50)) +
  theme_bw() 
hist_price


# lnprice -> closer to a normal distribution
hist_ln_price <- ggplot(data=df, aes(x=ln_price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.15,
                 color = "white", fill = "#440154", alpha = 0.7) +
  coord_cartesian(xlim = c(3.5, 6.5)) +
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.15), breaks = seq(0, 0.10, by = 0.05), labels = scales::percent_format(5L)) +
  labs(title = "Distribution of New York Airbnb log prices", x = "ln(price, US dollars)",y = "Percent")+
  theme_bw() 
hist_ln_price
```


## Exploratory Data Analysis

Some of the important predictor variables are related to the size: for example the total number of guests an apartment can accommodate and number of beds, number of bathrooms. The below box plots show the average price per number of guests. On the other hand, it can be seen that apartments with many guests have high average prices.


```{r fig.height=4, message=FALSE, warning=FALSE, include=FALSE, out.width='50%'}

# boxplot for different types of property
boxplot_property_type <- ggplot(df, aes(x = factor(f_property_type), y = price, fill = factor(f_property_type), color=factor(f_property_type))) +
  geom_boxplot(alpha=0.6, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_viridis(option = "D", discrete = TRUE) +
  scale_fill_viridis(option = "D", discrete = TRUE) +
  labs(x = "Accommodates (Person)",y = "Price (USD Dollar)", color = "Property Type", fill = "Property Type") + 
  theme_bw() +
  theme(legend.position = "top", panel.border = element_blank(), axis.text=element_text(size=8), plot.title = element_text(size = 12L, face = "bold", hjust = 0.5) ) +
  ggtitle("Property type distribution")

boxplot_property_type
# boxplot for different types of property and number of acco
boxplot_accomm_pr <- ggplot(df, aes(x = factor(n_accommodates), y = price, fill = factor(n_accommodates), color=factor(n_accommodates))) +
  geom_boxplot(alpha=0.6, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_viridis(option = "D", discrete = TRUE) +
  scale_fill_viridis(option = "D", discrete = TRUE) +
  labs(x = "Accommodates (Person)",y = "Price (USD Dollar)", color = "Accommodates", fill = "Accommodates") + 
  theme_bw() +
  theme(legend.position = "top", panel.border = element_blank(), axis.text=element_text(size=8), plot.title = element_text(size = 12L, face = "bold", hjust = 0.5) ) +
  ggtitle("Aaccommodates price distribution")

boxplot_accomm_pr
```


```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=4}
hist_price
boxplot_accomm_pr
```

## Modeling 

**Regressions** The best model gives the best prediction in the live data. Before turning to the modeling part of the project, it is worth mentioning that in order to avoid over fitting, the original data is split into two random parts by 20% to 80% ratio. Holdout set contains the 20% and the rest is work data set. In addition the k-fold cross-validation is a good way to find a model which gives the best prediction for the original data. For the purpose of this project 5-fold cross validation is used. This means splitting the data into five random samples and calculating and deciding based on the average of 5 CV RMSE result. Eight basic OLS regression models from simplest to the most complex one were used to find a better model to use for further analysis. The below model, Model 7 regression, had the lowest RMSE value. Further details are provided in the technical report. Model 7 consist of basic variables, basic additional variables, reviews variables, polynomial levels, amenities and interactions

```{r message=FALSE, warning=FALSE, include=FALSE}

# Part II 
#------------------------------------------
# Defining variables

# define variables
basic_lev <- c("n_accommodates", "f_property_type", "n_beds", "n_days_since", "flag_days_since")

# Factorized variables
basic_add <- c("f_bathroom", "f_neighbourhood_group_cleansed", "f_host_response_time")

# reviews
reviews <- c("f_number_of_reviews", "n_review_scores_rating", "n_reviews_per_month")

# higher orders
poly_lev <- c("n_accommodates2", "n_days_since2", "n_days_since3")

# Dummy Variables 
dummies <- grep("^d_.*", names(df), value = TRUE)


```


```{r include=FALSE}

# based on suggested grpaphs
X1 <- c("f_property_type * n_accommodates", "f_property_type * f_host_response_time")


# Additional dummies based on graphs suggestion
X2  <- c("f_property_type*d_air_conditioning", 
         "f_property_type*d_elevator",
         "f_property_type*d_dryer",
         "f_property_type*d_washer",
         "f_property_type*d_wifi",
         "f_property_type*d_kitchen", 
         "f_property_type*d_breakfast")


# all dummies with property type
X3  <- c("f_property_type*f_neighbourhood_group_cleansed", "n_accommodates*f_neighbourhood_group_cleansed",
         paste0("(f_property_type) * (",
                paste(dummies, collapse=" + "),")"))

```


```{r include=FALSE}

# Create models in levels models: 1-8
modellev1 <- " ~ n_accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews, poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies, X3),collapse = " + "))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
model_table_view <- data.frame(Model = c('M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8'),
                               Predictors = c('number of accommodates', 
                               'M1 + number of beds + number of days since first review + property type', 
                               'M2 + number of bathrooms + Neighbourhood groups + host reponse rate + reviews per month + average review score rating + number of reviews',
                               'M3 + squared term of guests + squared and cubic terms of number of days since first review',
                               'M4 + property type and number of guests interaction + property type and host response time interaction',
                               'M5 + property type interaction with adummies as air conditioning, elavator, dryer, washer, wifi, kitchen and breakfast',
                               'M6 + all other amenities',
                               'M7 + all other amenities, Neighbourhoods interacted with property type'))
model_table_viewxx <- model_table_view %>%
  kbl(caption = "New York Airbnb apartment price prediction Models") %>%
  kable_minimal(full_width = F, html_font = "Cambria")
```



```{r include=FALSE}

# Separate hold-out set #
#----------------------------------------
# create a holdout set (20% of observations)
smp_size <- floor(0.2 * nrow(df))

# Set the random number generator: It will make results reproducable
set.seed(12345)

# A) create ids:
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
holdout_ids <- sample(seq_len(nrow(df)), size = smp_size)
df$holdout <- 0
df$holdout[holdout_ids] <- 1

#Hold-out set Set
data_holdout <- df %>% filter(holdout == 1)

#Working data set
data_work <- df %>% filter(holdout == 0)
```


```{r message=FALSE, warning=FALSE, include=FALSE}

# Utilizing the Working data set:
#   a) estimating measures on the whole working sample (R2,BIC,RMSE)
#   b) Doing K-fold cross validation to get proper Test RMSE

## K = 5
k_folds=5
# Create the folds
set.seed(12345)

folds_i <- sample(rep(1:k_folds, length.out = nrow(data_work) ))
# Create results
model_results_cv <- list()


for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")

  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))

  # Initialize values
  rmse_train <- c()
  rmse_test <- c()

  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared

  # Do the k-fold estimation
  for (k in 1:k_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)

    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train[,yvar] %>% pull)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_test[,yvar] %>% pull)**(1/2)

  }

  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}

model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)

#skim(data_train$ln_days_since)

t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                 "Test RMSE")

# R2, BIC on full work data-n.
# In sample rmse: average on training data; avg test : average on test data

OLS_models <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(OLS_models) <- column_names
print(xtable(OLS_models, type = "latex", digits=c(0,0,0,2,0,2,2)), file = paste0(output, "OLS_models.tex"),
      include.rownames=FALSE, booktabs=TRUE, floating = FALSE)

# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))

model_result_plot_levels <- ggplot(data = t1_levels,
                                   aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
  geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
  scale_color_manual(name="",
                     values=c("#fde725","#440154")) +
  geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  theme_bw()
model_result_plot_levels


```



```{r fig.height=4, message=FALSE, warning=FALSE, include=FALSE, out.width='50%'}
OLS_models  %>%
  kbl(caption = "Models Evaluation") %>%
  kable_minimal(full_width = F, html_font = "Cambria")
```


```{r include=FALSE}

# Set lasso tuning parameters:
#----------------------------------------------------
# a) basic setup
train_control <- trainControl( method = "cv", number = k_folds)
# b) tell the actual lambda (penalty parameter) to use for lasso
tune_grid     <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# c) create a formula
# creating three predictors to be used for OLS, LASSO, Random forest, and GBM
predictors_1 <- c(basic_lev, basic_add, reviews, dummies)
predictors_2 <- c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies) #Model 7, best model based on CV RMSE


```

## Models

It is important to run and evaluate different models for a given data set. In order to predict apartment prices, the following models and algorithms were used. Naming them as following:

- **OLS** and **LASSO** using model 7 based CV-RMSE result

- **CART**, **Random Forest** , **GBM**  using basic level variables, basic additions, review variables and amenities as dummy variables.

Based on the below table of models, it is can be seen that GBM model has the best performance. 5-fold cross validation RMSE for the data is 65.38 USD RMSE which is 1.683 USD RMSE less than the second best model which is Random Forest. Moreover, The 5-fold cross validation RMSE for the GBM model using Holdout set is 64.38 USD RMSE indicating a better performance than other models illustrating a better performance from second best model of random forest by 1.671 USD RMSE. GBM model tend to be robust, thus, the selected model for this project is GBM BASIC TUNING model. 

```{r include=FALSE}
# OLS BASIC           
#################################

# Using OLS for the Basic variables
set.seed(12345)
system.time({
  ols_model <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = data_work,
    method = "lm",
    trControl = train_control
  )
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))


```



```{r include=FALSE}
# LASSO               
# -------------------------------------------------
# setting seed
set.seed(12345)
system.time({
  lasso_model <- caret::train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = data_work,
    method = "glmnet",
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    preProcess = c("center", "scale"),
    trControl = train_control
  )
})

print(lasso_model$bestTune$lambda)

lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed

print(lasso_coeffs)

lasso_coeffs_nz <- lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

# Evaluate model. CV error:
lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])

regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_nz, by = "variable", all=TRUE)
regression_coeffs %>%
  write.csv(file = paste0(output, "regression_coeffs.csv"))

```



```{r message=FALSE, warning=FALSE, include=FALSE}
# CART        
#-------------------------------------------
# setting seed
set.seed(12345)
system.time({
  cart_model <- train(
    formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
    data = data_work,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})


fancyRpartPlot(cart_model$finalModel, sub = "", palettes = "Purples")

```



```{r message=FALSE, warning=FALSE, include=FALSE}
# RANDOM FOREST     
#-------------------------------------------
# using all variables without their functional forms. Using predictor 1
# setting seed
# set tuning
tune_grid <- expand.grid(
  .mtry = c(8),
  .splitrule = "variance",
  .min.node.size = c(50)
)

# set seed
set.seed(12345)
system.time({
rf_model <- train(
  formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
})
rf_model
```


```{r include=FALSE}

# GBM              
#----------------------
# Basic GMB model
gbm_grid <-  expand.grid(interaction.depth = c(5, 10), # complexity of the tree
                         n.trees = 250, # Number of trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)


set.seed(12345)
system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
                     data = data_work,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model



```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model$finalModel$mtry,
  rf_model$finalModel$min.node.size
),
nrow=1, ncol=2,
dimnames = list("Model A",
                c("Min vars","Min nodes"))
)
kable(x = result_1, format = "latex", digits = 3) %>%
  cat(.,file= paste0(output,"rf_models_turning_choices.tex"))
```



```{r include=FALSE}
# FINAL MODELS         
#--------------------------
final_models <-
  list("OLS" = ols_model,
       "LASSO" = lasso_model,
       "CART" = cart_model,
       "Random Forest"= rf_model,
       "GBM"  = gbm_model
       )

results <- resamples(final_models) %>% summary()


```

```{r include=FALSE}
# Evaluating both data sets
result_3r <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV Rsquared" = ".")

result_3r

```


```{r include=FALSE}
# Evaluating both data sets
result_4 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

result_4

kable(x = result_4, format = "latex", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"final_models_cv_rmse.tex"))



# evaluate preferred model on the holdout set -----------------------------

result_5 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

result_5

kable(x = result_5, format = "latex", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"final_models_houldout_rmse.tex"))



```


```{r echo=FALSE, message=FALSE, warning=FALSE}
final_result4_5 <- cbind(result_4, result_5, result_3r)

final_result4_5 %>% 
  kbl() %>% 
  kable_minimal(full_width = F, html_font = "Cambria")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Diagnsotics
#-------------------------------------------------

# Variable Importance Plots 
#-------------------------------------------------
# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}


rf_model_var_imp <- importance(rf_model$finalModel)/1000
rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

```



```{r include=FALSE}

# full varimp plot, top 10 only
#-------------------------------------------

rf_model_var_imp_plot_b <- ggplot(rf_model_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color ="#440154", size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color="#440154", size=0.75, alpha = 0.6) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text.x = element_text(size=6), axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=6), axis.title.y = element_text(size=6)) +
  labs(title = "Top 10 important variables")
rf_model_var_imp_plot_b

```

```{r include=FALSE}

# 2) varimp plot grouped
#---------------------------------------------
# grouped variable importance - keep binaries created off factors together

varnames <- rf_model$finalModel$xNames
f_neighbourhood_group_cleansed_varnames <- grep("f_neighbourhood_group_cleansed",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_group_cleansed=f_neighbourhood_group_cleansed_varnames,
               f_property_type = f_property_type_varnames,
               f_bathroom = "f_bathroom",
               n_days_since = "n_days_since",
               n_accommodates = "n_accommodates",
               n_beds = "n_beds")

rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)
rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                            imp = rf_model_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_var_imp_grouped_plot <-
  ggplot(rf_model_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color="#440154", size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color="#440154", size=0.6) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text.x = element_text(size=6), axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=6), axis.title.y = element_text(size=6)) +
  labs(title = "Factor Variables Grouped")
rf_model_var_imp_grouped_plot


```

## Diagnostics

The best selected model, GBM, is an ensemble method which is a black box model, because it does not reveal the pattern of association that drive prediction. However, diagnostic tools can be used to uncover information about the patterns of association which drive prediction. Some of them are as following: 


**Variable Importance plot** it shows the average importance of fit when we use an x variable or group of x variables. Variable importance plot for Top 10 important variables shows that number of bathrooms, number of accommodates, Manhattan neighborhood are the most important along with amenities such as washer, and gym. The grouped variable importance shows that bathrooms, neighborhoods, number of accommodates are the most important variables. 

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=3.5}

# ploting the variable importance plot

rf_model_var_imp_plot_b
rf_model_var_imp_grouped_plot
```

**Partial Dependence Plot** it shows how average y differs for different values of x conditional on all other predictor variables. Partial dependence plot is based on predictors for the holdout set.  Partial dependence plot for number of accommodates and price shows that price increases as the number of accommodates. 

```{r message=FALSE, warning=FALSE, include=FALSE}

# Partial Dependence Plots 
# ----------------------------------------------------------------
# Number of accommodates
pdp_n_acc <- pdp::partial(rf_model, pred.var = "n_accommodates", pred.grid = distinct_(data_holdout, "n_accommodates"), train = data_train)
pdp_n_acc_plot <- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color="#440154", size=3) +
  geom_line(color="#440154", size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bw() +
  labs(title = "Number of Guests to Accommodates")
pdp_n_acc_plot

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Partial Dependence Plots 
# Property type
pdp_n_propertytype <- pdp::partial(rf_model, pred.var = "f_property_type", pred.grid = distinct_(data_holdout, "f_property_type"), train = data_train)
pdp_n_propertytype_plot <- pdp_n_propertytype %>%
  autoplot( ) +
  geom_point(color="#440154", size=4) +
  ylab("Predicted price") +
  xlab("Property type") +
  theme_bw() +
  labs(title = "Property Type")
pdp_n_propertytype_plot

```



**Actual vs Predicted Price** another post prediction diagnostics is comparing the predicted prices versus the actual prices. The figure below shows that prediction does a better job for lower than higher prices. 

```{r message=FALSE, warning=FALSE, include=FALSE}

# Subsample performance: RMSE / mean(y) ---------------------------------------

# ---- cheaper or more expensive flats - not used in book
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model, newdata = data_holdout))



######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )


b <- data_holdout_w_prediction %>%
  group_by(f_neighbourhood_group_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )

c <- data_holdout_w_prediction %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )


d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )

# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Neighbourhood", "", "", "")

result_3 <- rbind(line2, a, line1, c, line3, b, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))


result_3

options(knitr.kable.NA = '')
kable(x = result_3, format = "latex", booktabs=TRUE, linesep = "",digits = c(0,2,1,2), col.names = c("","RMSE","Mean price","RMSE/price")) %>%
  cat(.,file= paste0(output, "performance_across_subsamples.tex"))
options(knitr.kable.NA = NULL)


```

```{r message=FALSE, warning=FALSE, include=FALSE}

# FIGURES FOR FITTED VS ACTUAL OUTCOME VARIABLES #
##--------------------------------------------------

Ylev <- data_holdout[["price"]]

# Predicted values
prediction_holdout_pred <- as.data.frame(predict(gbm_model, newdata = data_holdout, interval="predict")) 

predictionlev_holdout <- cbind(data_holdout[,c("price","n_accommodates")],
                               prediction_holdout_pred)



# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout[,3] )
# Check the differences
d$elev <- d$ylev - d$predlev

# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = "#440154", size = 1,
             shape = 16, alpha = 0.5, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 350, yend =350), size=0.8, color="black", linetype=2) +
  labs(y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bw() 
level_vs_pred

```



```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=3.5}
pdp_n_acc_plot

level_vs_pred
```

## Conclusion
The goal of this report was to find a better model to predict Airbnb prices in New York for a small to mid-size apartments. Five models were illustrated to compare and contrast across models performance. GBM resulted to be the best model by 65.38 USD RMSE, besides this GBM model also shows better performance in holdout set with 64.38 USD RMSE. The second best model was basic Random Forest which has highlights meaningful characteristics about the nature of Airbnb apartments in New York. Key price drivers based on post prediction diagnostics are the number of bathroom, number of accommodates, and availability of amenities such as washer and gym. partial dependence plot also illustrated that the model better predicts Manhattan neighbourhood. 
